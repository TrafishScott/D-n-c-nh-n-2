import pandas as pd
import numpy as np
import xgboost as xgb
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix, 
    roc_auc_score, precision_score, recall_score, f1_score
)
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
import os

class RecommendationSystem:
    def __init__(self):
        self.df = None
        self.results = {}
        self.evaluations = {}
        self.categorical_cols = ["indrel", "indrel_1mes", "tiprel_1mes", "indresi", "indext", "canal_entrada", "nomprov"]
        self.numerical_cols = ["age", "antiguedad"]
        self.target_cols = []
        self.feature_cols = []
        self.models_trained = False
        self.label_encoders = {}  # L∆∞u tr·ªØ c√°c LabelEncoder ƒë√£ hu·∫•n luy·ªán
        
    def load_data(self, file_path):
        """ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV"""
        try:
            self.df = pd.read_csv(file_path, low_memory=False)
            print(f"üìã D·ªØ li·ªáu c√≥ {self.df.shape[0]} d√≤ng v√† {self.df.shape[1]} c·ªôt")
            
            # X√°c ƒë·ªãnh c√°c c·ªôt feature v√† target
            self.feature_cols = self.numerical_cols.copy()
            self.feature_cols.extend([col for col in self.categorical_cols if col in self.df.columns])
            self.target_cols = [col for col in self.df.columns if col.startswith("ind_") and col != "ind_empleado"]
            
            print(f"‚úÖ Feature columns: {self.feature_cols}")
            print(f"‚úÖ Target columns: {self.target_cols}")
            return True
        except Exception as e:
            print(f"‚ùå L·ªói khi ƒë·ªçc file: {str(e)}")
            return False
    
    def preprocess_data(self):
        """X·ª≠ l√Ω d·ªØ li·ªáu tr∆∞·ªõc khi hu·∫•n luy·ªán v√† l∆∞u c√°c LabelEncoder"""
        # X·ª≠ l√Ω c·ªôt ph√¢n lo·∫°i
        for col in self.categorical_cols:
            if col in self.df.columns:
                self.df[col] = self.df[col].astype(str)
                
                # T·∫°o v√† l∆∞u LabelEncoder
                encoder = LabelEncoder()
                self.df[col] = encoder.fit_transform(self.df[col])
                self.label_encoders[col] = encoder
        
        # X·ª≠ l√Ω c·ªôt s·ªë
        for col in self.numerical_cols:
            if col in self.df.columns:
                self.df[col] = pd.to_numeric(self.df[col], errors='coerce')
                self.df[col] = self.df[col].fillna(self.df[col].median())
        
        print("‚úÖ Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu ho√†n t·∫•t!")
        
    def evaluate_model(self, model, X_test, y_test, target_name):
        """ƒê√°nh gi√° m√¥ h√¨nh chi ti·∫øt"""
        # D·ª± ƒëo√°n
        y_pred = model.predict(X_test)
        
        # D·ª± ƒëo√°n x√°c su·∫•t
        try:
            y_pred_proba = model.predict_proba(X_test)[:, 1]
        except:
            y_pred_proba = None
        
        # Metrics
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, zero_division=0)
        recall = recall_score(y_test, y_pred, zero_division=0)
        f1 = f1_score(y_test, y_pred, zero_division=0)
        cm = confusion_matrix(y_test, y_pred)
        
        # AUC-ROC
        auc_roc = None
        if y_pred_proba is not None:
            auc_roc = roc_auc_score(y_test, y_pred_proba)
        
        # In th√¥ng tin ƒë√°nh gi√°
        print(f"\nüìä K·∫æT QU·∫¢ ƒê√ÅNH GI√Å CHO {target_name}")
        print("-" * 50)
        print(f"ƒê·ªô ch√≠nh x√°c (Accuracy): {accuracy:.4f}")
        print(f"Precision: {precision:.4f}")
        print(f"Recall: {recall:.4f}")
        print(f"F1-Score: {f1:.4f}")
        if auc_roc:
            print(f"AUC-ROC: {auc_roc:.4f}")
        
        # Tr·∫£ v·ªÅ k·∫øt qu·∫£ ƒë√°nh gi√°
        evaluation = {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'confusion_matrix': cm
        }
        
        if auc_roc:
            evaluation['auc_roc'] = auc_roc
            
        return evaluation
    
    def train_models(self):
        """Hu·∫•n luy·ªán m√¥ h√¨nh cho t·ª´ng s·∫£n ph·∫©m"""
        if self.df is None:
            print("‚ùå C·∫ßn t·∫£i d·ªØ li·ªáu tr∆∞·ªõc khi hu·∫•n luy·ªán!")
            return False
        
        # Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu
        self.preprocess_data()
        
        # Hu·∫•n luy·ªán m√¥ h√¨nh cho t·ª´ng s·∫£n ph·∫©m
        for target_col in self.target_cols:
            print(f"\nüîç ƒêang hu·∫•n luy·ªán m√¥ h√¨nh cho s·∫£n ph·∫©m: {target_col}")
            
            # Ch·ªâ s·ª≠ d·ª•ng c√°c c·ªôt feature c√≥ trong dataset
            valid_features = [col for col in self.feature_cols if col in self.df.columns]
            
            # ƒê·∫£m b·∫£o kh√¥ng c√≥ gi√° tr·ªã NaN
            X = self.df[valid_features].copy()
            for col in X.columns:
                if X[col].dtype == 'object':
                    X[col] = X[col].astype(str)
                    X[col] = LabelEncoder().fit_transform(X[col])
                elif X[col].isnull().any():
                    X[col] = X[col].fillna(X[col].median())
            
            # X·ª≠ l√Ω target
            if target_col in self.df.columns:
                y = self.df[target_col].copy()
                
                if y.dtype == 'object':
                    y = y.astype(str)
                    y = LabelEncoder().fit_transform(y)
                
                # Ki·ªÉm tra n·∫øu ch·ªâ c√≥ m·ªôt l·ªõp
                if len(y.unique()) == 1:
                    print(f"‚ö†Ô∏è C·ªôt {target_col} ch·ªâ c√≥ m·ªôt gi√° tr·ªã {y.unique()[0]}. B·ªè qua!")
                    continue
                
                # Chia t·∫≠p train - test
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
                
                try:
                    # Hu·∫•n luy·ªán m√¥ h√¨nh
                    model = XGBClassifier(
                        n_estimators=100,
                        learning_rate=0.1,
                        max_depth=6,
                        objective='binary:logistic',
                        eval_metric='logloss'
                    )
                    
                    model.fit(X_train, y_train)
                    
                    # ƒê√°nh gi√° m√¥ h√¨nh
                    eval_results = self.evaluate_model(model, X_test, y_test, target_col)
                    
                    # L∆∞u k·∫øt qu·∫£
                    self.results[target_col] = {
                        "model": model,
                        "feature_importance": dict(zip(valid_features, model.feature_importances_))
                    }
                    
                    self.evaluations[target_col] = eval_results
                    
                except Exception as e:
                    print(f"‚ùå L·ªói khi hu·∫•n luy·ªán m√¥ h√¨nh cho {target_col}: {str(e)}")
            else:
                print(f"‚ùå Kh√¥ng t√¨m th·∫•y c·ªôt {target_col} trong d·ªØ li·ªáu!")
        
        # Hi·ªÉn th·ªã so s√°nh hi·ªáu su·∫•t
        self.compare_models()
        
        self.models_trained = True
        print("\n‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t!")
        return True
    
    def compare_models(self):
        """So s√°nh hi·ªáu su·∫•t c√°c m√¥ h√¨nh"""
        if not self.evaluations:
            return
            
        print("\nüìà SO S√ÅNH HI·ªÜU SU·∫§T C√ÅC M√î H√åNH")
        print("-" * 50)
        
        # T·∫°o b·∫£ng so s√°nh
        comparison = pd.DataFrame({
            'S·∫£n ph·∫©m': [],
            'ƒê·ªô ch√≠nh x√°c': [],
            'Precision': [],
            'Recall': [],
            'F1-Score': [],
            'AUC-ROC': []
        })
        
        for target, eval_results in self.evaluations.items():
            new_row = pd.DataFrame({
                'S·∫£n ph·∫©m': [target],
                'ƒê·ªô ch√≠nh x√°c': [eval_results['accuracy']],
                'Precision': [eval_results['precision']],
                'Recall': [eval_results['recall']],
                'F1-Score': [eval_results['f1_score']]
            })
            
            if 'auc_roc' in eval_results:
                new_row['AUC-ROC'] = eval_results['auc_roc']
            else:
                new_row['AUC-ROC'] = None
            
            comparison = pd.concat([comparison, new_row], ignore_index=True)
        
        # S·∫Øp x·∫øp theo F1-Score
        comparison = comparison.sort_values('F1-Score', ascending=False)
        print(comparison.to_string(index=False))
        
        # Hi·ªÉn th·ªã ƒë·∫∑c tr∆∞ng quan tr·ªçng
        self.show_feature_importance()
    
    def show_feature_importance(self):
        """Hi·ªÉn th·ªã ƒë·∫∑c tr∆∞ng quan tr·ªçng nh·∫•t"""
        if not self.results:
            return
            
        print("\nüìä ƒê·∫∂C TR∆ØNG QUAN TR·ªåNG NH·∫§T TR√äN T·∫§T C·∫¢ C√ÅC M√î H√åNH")
        print("-" * 50)
        
        # T√≠nh ƒëi·ªÉm quan tr·ªçng trung b√¨nh
        all_features = {}
        for target, result in self.results.items():
            feature_importance = result["feature_importance"]
            
            for feature, importance in feature_importance.items():
                if feature not in all_features:
                    all_features[feature] = []
                
                all_features[feature].append(importance)
        
        # T√≠nh trung b√¨nh v√† ƒë·ªô l·ªách chu·∫©n
        feature_summary = pd.DataFrame({
            'ƒê·∫∑c tr∆∞ng': [],
            'ƒêi·ªÉm t·∫ßm quan tr·ªçng trung b√¨nh': [],
            'ƒê·ªô l·ªách chu·∫©n': []
        })
        
        for feature, scores in all_features.items():
            new_row = pd.DataFrame({
                'ƒê·∫∑c tr∆∞ng': [feature],
                'ƒêi·ªÉm t·∫ßm quan tr·ªçng trung b√¨nh': [np.mean(scores)],
                'ƒê·ªô l·ªách chu·∫©n': [np.std(scores)]
            })
            
            feature_summary = pd.concat([feature_summary, new_row], ignore_index=True)
        
        # S·∫Øp x·∫øp theo ƒëi·ªÉm trung b√¨nh
        feature_summary = feature_summary.sort_values('ƒêi·ªÉm t·∫ßm quan tr·ªçng trung b√¨nh', ascending=False)
        print(feature_summary.to_string(index=False))
    
    def preprocess_customer_data(self, customer_data):
        """Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu kh√°ch h√†ng m·ªõi"""
        # X·ª≠ l√Ω c·ªôt ph√¢n lo·∫°i
        for col in self.categorical_cols:
            if col in customer_data.columns:
                customer_data[col] = customer_data[col].astype(str)
                
                # S·ª≠ d·ª•ng LabelEncoder ƒë√£ l∆∞u
                if col in self.label_encoders:
                    encoder = self.label_encoders[col]
                    # X·ª≠ l√Ω gi√° tr·ªã m·ªõi kh√¥ng c√≥ trong t·∫≠p hu·∫•n luy·ªán
                    for i, val in enumerate(customer_data[col]):
                        if val not in encoder.classes_:
                            print(f"‚ö†Ô∏è Ph√°t hi·ªán gi√° tr·ªã m·ªõi '{val}' trong c·ªôt '{col}'. Thay th·∫ø b·∫±ng gi√° tr·ªã ph·ªï bi·∫øn nh·∫•t.")
                            # T√¨m gi√° tr·ªã ph·ªï bi·∫øn nh·∫•t trong t·∫≠p hu·∫•n luy·ªán
                            most_common_val = encoder.classes_[0]  # M·∫∑c ƒë·ªãnh l·∫•y gi√° tr·ªã ƒë·∫ßu ti√™n
                            customer_data.loc[i, col] = most_common_val
                    
                    # √Åp d·ª•ng transform
                    customer_data[col] = encoder.transform(customer_data[col])
        
        # X·ª≠ l√Ω c·ªôt s·ªë
        for col in self.numerical_cols:
            if col in customer_data.columns:
                customer_data[col] = pd.to_numeric(customer_data[col], errors='coerce')
                if customer_data[col].isnull().any() and col in self.df.columns:
                    customer_data[col] = customer_data[col].fillna(self.df[col].median())
        
        return customer_data
    
    def predict_for_customer(self, customer_data):
        """D·ª± ƒëo√°n c√°c s·∫£n ph·∫©m ph√π h·ª£p cho kh√°ch h√†ng m·ªõi"""
        if not self.models_trained:
            print("‚ùå C·∫ßn hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc khi d·ª± ƒëo√°n!")
            return None
        
        # Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu kh√°ch h√†ng
        customer_data = self.preprocess_customer_data(customer_data)
        
        # D·ª± ƒëo√°n
        predictions = {}
        
        for product, result in self.results.items():
            model = result["model"]
            valid_features = list(result["feature_importance"].keys())
            
            # Ki·ªÉm tra ƒë·ªß c√°c c·ªôt feature
            has_all_features = all(feature in customer_data.columns for feature in valid_features)
            if not has_all_features:
                print(f"‚ö†Ô∏è Thi·∫øu m·ªôt s·ªë c·ªôt ƒë·∫∑c tr∆∞ng cho s·∫£n ph·∫©m {product}")
                continue
            
            # D·ª± ƒëo√°n
            try:
                X_customer = customer_data[valid_features]
                proba = model.predict_proba(X_customer)[0, 1]  # X√°c su·∫•t l·ªõp d∆∞∆°ng
                pred = 1 if proba >= 0.5 else 0
                
                predictions[product] = {
                    "prediction": pred,
                    "probability": proba
                }
            except Exception as e:
                print(f"‚ùå L·ªói khi d·ª± ƒëo√°n cho {product}: {str(e)}")
        
        # Chuy·ªÉn k·∫øt qu·∫£ th√†nh DataFrame
        pred_df = pd.DataFrame({
            'S·∫£n ph·∫©m': [],
            'D·ª± ƒëo√°n': [],
            'X√°c su·∫•t (%)': []
        })
        
        for product, result in predictions.items():
            new_row = pd.DataFrame({
                'S·∫£n ph·∫©m': [product],
                'D·ª± ƒëo√°n': [result['prediction']],
                'X√°c su·∫•t (%)': [result['probability'] * 100]
            })
            
            pred_df = pd.concat([pred_df, new_row], ignore_index=True)
        
        # S·∫Øp x·∫øp theo x√°c su·∫•t gi·∫£m d·∫ßn
        pred_df = pred_df.sort_values('X√°c su·∫•t (%)', ascending=False)
        
        return pred_df
    
    def get_new_customer_data(self):
        """Nh·∫≠p d·ªØ li·ªáu kh√°ch h√†ng m·ªõi t·ª´ ng∆∞·ªùi d√πng"""
        print("\nüìù NH·∫¨P TH√îNG TIN KH√ÅCH H√ÄNG M·ªöI")
        print("-" * 50)
        
        customer_data = {}
        
        # Nh·∫≠p d·ªØ li·ªáu s·ªë
        for col in self.numerical_cols:
            while True:
                try:
                    value = input(f"Nh·∫≠p {col} (v√≠ d·ª•: age = 45, antiguedad = 15): ")
                    customer_data[col] = float(value)
                    break
                except ValueError:
                    print("‚ùå Vui l√≤ng nh·∫≠p m·ªôt s·ªë h·ª£p l·ªá!")
        
        # Nh·∫≠p d·ªØ li·ªáu ph√¢n lo·∫°i
        for col in self.categorical_cols:
            if col in self.label_encoders:
                encoder = self.label_encoders[col]
                print(f"\nGi√° tr·ªã ƒë√£ bi·∫øt cho {col}: {', '.join(encoder.classes_)}")
            
            value = input(f"Nh·∫≠p {col} (v√≠ d·ª•: \nindrel = 1\nindrel_1mes = 1\ntiprel_1mes = A\nindresi = S\nindext = N\ncanal_entrada = KAF\nnomprov = MADRID)\n\nNh·∫≠p: ")
            customer_data[col] = value
        
        # Chuy·ªÉn th√†nh DataFrame
        df_customer = pd.DataFrame(customer_data, index=[0])
        
        return df_customer

    def print_unique_values(self):
        """In ra c√°c gi√° tr·ªã duy nh·∫•t cho t·ª´ng c·ªôt ph√¢n lo·∫°i"""
        if self.df is None:
            print("‚ùå C·∫ßn t·∫£i d·ªØ li·ªáu tr∆∞·ªõc!")
            return
            
        print("\nüìä C√ÅC GI√Å TR·ªä DUY NH·∫§T TRONG C·ªòT PH√ÇN LO·∫†I")
        print("-" * 50)
        
        for col in self.categorical_cols:
            if col in self.df.columns:
                unique_values = self.df[col].astype(str).unique()
                print(f"{col}: {', '.join(unique_values)}")
        
        print("\nüìä TH·ªêNG K√ä C√ÅC C·ªòT S·ªê")
        print("-" * 50)
        
        for col in self.numerical_cols:
            if col in self.df.columns:
                stats = self.df[col].describe()
                print(f"{col}:")
                print(f"  Min: {stats['min']}")
                print(f"  Max: {stats['max']}")
                print(f"  Mean: {stats['mean']}")
                print(f"  Median: {stats['50%']}")

def display_menu():
    """Hi·ªÉn th·ªã menu ch√≠nh"""
    print("\n" + "=" * 50)
    print("üåü H·ªÜ TH·ªêNG KHUY·∫æN NGH·ªä S·∫¢N PH·∫®M üåü".center(50))
    print("=" * 50)
    print("1. Hu·∫•n luy·ªán m√¥ h√¨nh")
    print("2. D·ª± ƒëo√°n cho kh√°ch h√†ng m·ªõi")
    print("3. Hi·ªÉn th·ªã th√¥ng tin d·ªØ li·ªáu")
    print("4. Tho√°t")
    print("=" * 50)
    
    choice = input("Ch·ªçn ch·ª©c nƒÉng (1-4): ")
    return choice

def main():
    """H√†m ch√≠nh c·ªßa ch∆∞∆°ng tr√¨nh"""
    system = RecommendationSystem()
    
    while True:
        choice = display_menu()
        
        if choice == '1':
            print("\nüîÑ HU·∫§N LUY·ªÜN M√î H√åNH")
            print("-" * 50)
            
            # Nh·∫≠p ƒë∆∞·ªùng d·∫´n file d·ªØ li·ªáu
            file_path = input("Nh·∫≠p ƒë∆∞·ªùng d·∫´n file CSV (nh·∫•n Enter ƒë·ªÉ s·ª≠ d·ª•ng ƒë∆∞·ªùng d·∫´n m·∫∑c ƒë·ªãnh): ")
            if not file_path:
                file_path = "test.csv"
            
            # T·∫£i d·ªØ li·ªáu
            if system.load_data(file_path):
                # Hu·∫•n luy·ªán m√¥ h√¨nh
                system.train_models()
            
            input("\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
            
        elif choice == '2':
            if not system.models_trained:
                print("\n‚ùå C·∫ßn hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc khi d·ª± ƒëo√°n!")
                input("\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
                continue
            
            print("\nüîÆ D·ª∞ ƒêO√ÅN CHO KH√ÅCH H√ÄNG M·ªöI")
            print("-" * 50)
            
            # Nh·∫≠p d·ªØ li·ªáu kh√°ch h√†ng m·ªõi
            customer_data = system.get_new_customer_data()
            
            # D·ª± ƒëo√°n
            predictions = system.predict_for_customer(customer_data)
            
            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            if predictions is not None:
                print("\nüéØ C√ÅC S·∫¢N PH·∫®M PH√ô H·ª¢P CHO KH√ÅCH H√ÄNG:")
                print(predictions)
                
                # Hi·ªÉn th·ªã c√°c s·∫£n ph·∫©m ƒë∆∞·ª£c khuy·∫øn ngh·ªã
                recommended = predictions[predictions['X√°c su·∫•t (%)'] > 50]
                if not recommended.empty:
                    print("\nüîÜ C√ÅC S·∫¢N PH·∫®M ƒê∆Ø·ª¢C KHUY·∫æN NGH·ªä:")
                    print(recommended)
                else:
                    print("\n‚ö†Ô∏è Kh√¥ng c√≥ s·∫£n ph·∫©m n√†o c√≥ x√°c su·∫•t cao (>50%)")
            
            input("\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
            
        elif choice == '3':
            if system.df is None:
                print("\n‚ùå C·∫ßn t·∫£i d·ªØ li·ªáu tr∆∞·ªõc!")
                input("\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
                continue
                
            print("\nüìä TH√îNG TIN D·ªÆ LI·ªÜU")
            system.print_unique_values()
            input("\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
            
        elif choice == '4':
            print("\nüëã C·∫£m ∆°n b·∫°n ƒë√£ s·ª≠ d·ª•ng h·ªá th·ªëng!")
            break
            
        else:
            print("\n‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá! Vui l√≤ng ch·ªçn l·∫°i.")

if __name__ == "__main__":
    main()